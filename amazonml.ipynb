{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psbYn_fpyNUL",
        "outputId": "ecb16f45-e911-44d4-8901-68d56eec775f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import cv2\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load the dataset\n",
        "train_file = \"dataset/train.csv\"\n",
        "test_file = \"dataset/test.csv\"\n",
        "constants_file = \"src/constants.py\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checking if image links are working...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [03:18<00:00,  1.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image link working percentage: 100.0%\n",
            "Extracting entity consistency info...\n",
            "Unique entity names: ['item_weight' 'item_volume' 'voltage' 'wattage'\n",
            " 'maximum_weight_recommendation' 'height' 'depth' 'width']\n",
            "Unique entity values by entity name:\n",
            "entity_name\n",
            "depth                            [21.0 centimetre, 20.5 centimetre, 63.0 millim...\n",
            "height                           [95.0 centimetre, 46.5 millimetre, 71.0 centim...\n",
            "item_volume                      [1.0 cup, 4.0 gallon, 10.0 ounce, 30.0 millili...\n",
            "item_weight                      [500.0 gram, 0.709 gram, 1400 milligram, 30.0 ...\n",
            "maximum_weight_recommendation    [15 kilogram, 350 pound, 120 kilogram, 7 kilog...\n",
            "voltage                          [48.0 volt, 36.0 volt, [100.0, 240.0] volt, 12...\n",
            "wattage                          [800.0 watt, 150.0 watt, 30.0 watt, 250.0 watt...\n",
            "width                            [22.0 millimetre, 20.0 centimetre, 9.0 centime...\n",
            "Name: entity_value, dtype: object\n",
            "Checking for missing values...\n",
            "Missing values in training data:\n",
            "image_link      0\n",
            "group_id        0\n",
            "entity_name     0\n",
            "entity_value    0\n",
            "dtype: int64\n",
            "Missing values in test data:\n",
            "index          0\n",
            "image_link     0\n",
            "group_id       0\n",
            "entity_name    0\n",
            "dtype: int64\n",
            "Extracting allowed units from constants.py...\n",
            "Allowed units: ['{', '{unit for entity in entity_unit_map for unit in entity_unit_map[entity]}']\n",
            "Sampling 100 rows for testing...\n",
            "Train sample:\n",
            "                                               image_link  group_id  \\\n",
            "108085  https://m.media-amazon.com/images/I/71CjttrsKP...    459516   \n",
            "227578  https://m.media-amazon.com/images/I/61CZna5JoY...    311997   \n",
            "122528  https://m.media-amazon.com/images/I/61U0ZQ-le9...    529606   \n",
            "27374   https://m.media-amazon.com/images/I/71vquTlPrM...    507467   \n",
            "190808  https://m.media-amazon.com/images/I/61CoLcx3u8...    351134   \n",
            "\n",
            "        entity_name     entity_value  \n",
            "108085  item_weight  700.0 milligram  \n",
            "227578       height       22.44 inch  \n",
            "122528  item_weight        8.0 ounce  \n",
            "27374   item_weight   114.0 kilogram  \n",
            "190808        depth        18.0 inch  \n",
            "Test sample:\n",
            "         index                                         image_link  group_id  \\\n",
            "791        792  https://m.media-amazon.com/images/I/31Vxf54alK...    843434   \n",
            "121527  121617  https://m.media-amazon.com/images/I/71d1QxHjIe...    953313   \n",
            "29017    29052  https://m.media-amazon.com/images/I/5193dYHVg+...    913156   \n",
            "116583  116663  https://m.media-amazon.com/images/I/71BRe7uTXZ...    749917   \n",
            "98651    98725  https://m.media-amazon.com/images/I/61AeHXKENg...    311997   \n",
            "\n",
            "        entity_name  \n",
            "791           depth  \n",
            "121527  item_weight  \n",
            "29017        height  \n",
            "116583  item_weight  \n",
            "98651        height  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load train and test data\n",
        "train_data = pd.read_csv(train_file)\n",
        "test_data = pd.read_csv(test_file)\n",
        "\n",
        "# Question 1: Check if the image links are working\n",
        "def check_image_links(data, n_samples=100):\n",
        "    working_links = []\n",
        "    for i, url in enumerate(tqdm(data['image_link'].sample(n_samples))):\n",
        "        try:\n",
        "            response = requests.get(url, timeout=5)\n",
        "            if response.status_code == 200:\n",
        "                working_links.append(True)\n",
        "            else:\n",
        "                working_links.append(False)\n",
        "        except:\n",
        "            working_links.append(False)\n",
        "    return working_links\n",
        "\n",
        "# Question 2: Extract unique entity names and check consistency of entity values\n",
        "def check_entity_consistency(train_data):\n",
        "    entity_types = train_data['entity_name'].unique()\n",
        "    print(f\"Unique entity names: {entity_types}\")\n",
        "    entity_values = train_data.groupby('entity_name')['entity_value'].apply(lambda x: x.unique())\n",
        "    return entity_values\n",
        "\n",
        "# Question 3: List of allowed units from constants.py\n",
        "def extract_allowed_units(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = f.read()\n",
        "    allowed_units = []\n",
        "    # Assuming the units are in a dictionary format\n",
        "    lines = data.split('\\n')\n",
        "    for line in lines:\n",
        "        if \"=\" in line:\n",
        "            key, value = line.split(\"=\")\n",
        "            allowed_units.append(value.strip())\n",
        "    return allowed_units\n",
        "\n",
        "# Question 4: Check if data has any inconsistencies/missing values\n",
        "def check_data_issues(data):\n",
        "    missing_values = data.isnull().sum()\n",
        "    return missing_values\n",
        "\n",
        "# Updated sampling function to handle small datasets\n",
        "def sample_test_data(train_data, test_data, n_samples=100):\n",
        "    train_size = len(train_data)\n",
        "    test_size = len(test_data)\n",
        "\n",
        "    # Ensure we don't sample more than available rows\n",
        "    train_sample_size = min(train_size, n_samples)\n",
        "    test_sample_size = min(test_size, n_samples)\n",
        "\n",
        "    # Sampling train and test data\n",
        "    train_sample = train_data.sample(train_sample_size)\n",
        "    test_sample = test_data.sample(test_sample_size)\n",
        "\n",
        "    return train_sample, test_sample\n",
        "\n",
        "# Call this new function\n",
        "train_sample, test_sample = sample_test_data(train_data, test_data)\n",
        "\n",
        "# Function to run all checks\n",
        "def run_all_checks(train_data, test_data, constants_file):\n",
        "    print(\"Checking if image links are working...\")\n",
        "    image_link_status = check_image_links(train_data)\n",
        "    print(f\"Image link working percentage: {sum(image_link_status) / len(image_link_status) * 100}%\")\n",
        "\n",
        "    print(\"Extracting entity consistency info...\")\n",
        "    entity_values = check_entity_consistency(train_data)\n",
        "    print(\"Unique entity values by entity name:\")\n",
        "    print(entity_values)\n",
        "\n",
        "    print(\"Checking for missing values...\")\n",
        "    train_missing = check_data_issues(train_data)\n",
        "    test_missing = check_data_issues(test_data)\n",
        "    print(f\"Missing values in training data:\\n{train_missing}\")\n",
        "    print(f\"Missing values in test data:\\n{test_missing}\")\n",
        "\n",
        "    print(\"Extracting allowed units from constants.py...\")\n",
        "    allowed_units = extract_allowed_units(constants_file)\n",
        "    print(f\"Allowed units: {allowed_units}\")\n",
        "\n",
        "    print(\"Sampling 100 rows for testing...\")\n",
        "    train_sample, test_sample = sample_test_data(train_data, test_data)\n",
        "    print(f\"Train sample:\\n{train_sample.head()}\")\n",
        "    print(f\"Test sample:\\n{test_sample.head()}\")\n",
        "\n",
        "    return train_sample, test_sample\n",
        "\n",
        "# Run the checks\n",
        "train_sample, test_sample = run_all_checks(train_data, test_data, constants_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhO25mCJ0mIj",
        "outputId": "b9894602-fdc4-4306-d47d-3f3ddf5717b9"
      },
      "outputs": [],
      "source": [
        "!pip install pytesseract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zp0fqWAc0Yr6"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pytesseract\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import random\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJn_4CG91CBj",
        "outputId": "e28a96e1-b6db-487f-f673-918c063a316f"
      },
      "outputs": [],
      "source": [
        "!apt-get install tesseract-ocr -y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r5TLNp5l1FJI"
      },
      "outputs": [],
      "source": [
        "import pytesseract\n",
        "pytesseract.pytesseract.tesseract_cmd = r'C:\\Tesseract-OCR\\tesseract.exe'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7ZzLNG61rle",
        "outputId": "db8ce9b8-cf95-43ae-ca01-adea26d2e5ea"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTIJhQLs0ptc",
        "outputId": "b24affae-3913-42e8-8a4f-066fde967bd9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 522/263859 [06:43<58:45:28,  1.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Invalid image URL or non-image content at: https://m.media-amazon.com/images/I/1yw53vfQtS.jpg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 1098/263859 [13:56<79:31:38,  1.09s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error downloading image from https://m.media-amazon.com/images/I/41NH8WgeBOL.jpg: image file is truncated (2 bytes not processed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  1%|          | 1764/263859 [22:03<52:27:39,  1.39it/s]"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import requests\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from io import BytesIO\n",
        "import pytesseract\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load sampletrain.csv data\n",
        "train_df = pd.read_csv(\"dataset/train.csv\")\n",
        "test_df = pd.read_csv(\"dataset/test.csv\")\n",
        "\n",
        "# Function to download and preprocess image\n",
        "def load_image_from_url(image_url):\n",
        "    try:\n",
        "        response = requests.get(image_url)\n",
        "        # Check if the response is valid and the content type is an image\n",
        "        if response.status_code == 200 and 'image' in response.headers['Content-Type']:\n",
        "            img = Image.open(BytesIO(response.content))\n",
        "            img = img.resize((128, 128))  # Resizing images to standard size for CNN\n",
        "            img = np.array(img)\n",
        "            if img.shape[-1] == 4:  # Handle transparency in PNG\n",
        "                img = img[..., :3]\n",
        "            return img / 255.0  # Normalize image\n",
        "        else:\n",
        "            print(f\"Invalid image URL or non-image content at: {image_url}\")\n",
        "            return np.zeros((128, 128, 3))  # Return a black image as a placeholder\n",
        "    except UnidentifiedImageError:\n",
        "        print(f\"UnidentifiedImageError for URL: {image_url}\")\n",
        "        return np.zeros((128, 128, 3))  # Return a black image as a placeholder\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading image from {image_url}: {e}\")\n",
        "        return np.zeros((128, 128, 3))  # Return a black image as a placeholder\n",
        "\n",
        "# Function to extract text using OCR\n",
        "def extract_text_from_image(image_url):\n",
        "    try:\n",
        "        response = requests.get(image_url)\n",
        "        if response.status_code == 200 and 'image' in response.headers['Content-Type']:\n",
        "            img = Image.open(BytesIO(response.content))\n",
        "            text = pytesseract.image_to_string(img)\n",
        "            return text\n",
        "        else:\n",
        "            print(f\"Invalid image URL or non-image content at: {image_url}\")\n",
        "            return \"\"  # Return empty string for non-image content\n",
        "    except UnidentifiedImageError:\n",
        "        print(f\"UnidentifiedImageError for URL: {image_url}\")\n",
        "        return \"\"  # Return empty string for invalid images\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from {image_url}: {e}\")\n",
        "        return \"\"  # Return empty string in case of error\n",
        "\n",
        "# Apply to the dataset with progress bar\n",
        "tqdm.pandas()  # Enable progress_apply for pandas\n",
        "\n",
        "train_df['image_data'] = train_df['image_link'].progress_apply(load_image_from_url)\n",
        "train_df['ocr_text'] = train_df['image_link'].progress_apply(extract_text_from_image)\n",
        "\n",
        "test_df['image_data'] = test_df['image_link'].progress_apply(load_image_from_url)\n",
        "test_df['ocr_text'] = test_df['image_link'].progress_apply(extract_text_from_image)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "204jXrojAs9Q",
        "outputId": "abcf61f0-9a54-4ebc-ae7b-a17cafaa23f4"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation to boost the number of images for certain entities\n",
        "data_gen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Sample augmented images\n",
        "image_sample = train_df['image_data'].iloc[0].reshape((1, 128, 128, 3))  # Sample image for augmentation\n",
        "augmented_images = data_gen.flow(image_sample, batch_size=1)\n",
        "\n",
        "# Plot augmented images\n",
        "for i in range(5):\n",
        "    augmented_image = next(augmented_images)[0]\n",
        "    plt.imshow(augmented_image)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shKe-x7IP2V2",
        "outputId": "c807e12f-c928-47a5-cfa0-8c68dbdeed76"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_cnn_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='linear'))  # Output a numeric value (like item_weight)\n",
        "    return model\n",
        "\n",
        "# Instantiate and compile the model\n",
        "cnn_model = create_cnn_model()\n",
        "cnn_model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')\n",
        "\n",
        "# Convert images for CNN training\n",
        "X_images = np.stack(train_df['image_data'].values)\n",
        "\n",
        "# Ensure y_values is numeric\n",
        "y_values = pd.to_numeric(train_df['entity_value'], errors='coerce')\n",
        "\n",
        "# Check and handle NaNs if necessary\n",
        "if y_values.isna().any():\n",
        "    print(\"Warning: Some values in 'entity_value' could not be converted to numeric.\")\n",
        "    # Optionally handle NaNs here (e.g., impute or remove them)\n",
        "    y_values = y_values.fillna(0)  # Example: fill NaNs with 0\n",
        "\n",
        "# Convert to numpy array\n",
        "y_values = y_values.values\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_images, y_values, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure the shapes are correct\n",
        "print(f\"Shape of X_train: {X_train.shape}\")\n",
        "print(f\"Shape of y_train: {y_train.shape}\")\n",
        "\n",
        "# Ensure y_train and y_val are float32\n",
        "y_train = y_train.astype('float32')\n",
        "y_val = y_val.astype('float32')\n",
        "\n",
        "# Train the CNN model\n",
        "cnn_model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOky5crQRskS",
        "outputId": "0d9007bc-ee26-4609-917e-ef2db8384947"
      },
      "outputs": [],
      "source": [
        "# Use the OCR output for text-based model\n",
        "def text_based_model(ocr_text):\n",
        "    # Simple model that analyzes OCR text (could be more sophisticated)\n",
        "    if 'gram' in ocr_text.lower():\n",
        "        return 'weight'\n",
        "    elif 'volt' in ocr_text.lower():\n",
        "        return 'voltage'\n",
        "    elif 'watt' in ocr_text.lower():\n",
        "        return 'wattage'\n",
        "    # Add more entity handling rules as needed\n",
        "    return None\n",
        "\n",
        "# Apply the OCR-based model on the dataset\n",
        "train_df['predicted_entity'] = train_df['ocr_text'].apply(text_based_model)\n",
        "\n",
        "# Convert text-based predictions to numerical values for ensemble\n",
        "def entity_to_numeric(entity):\n",
        "    # Mapping text-based entities to simple numeric placeholders\n",
        "    entity_map = {'weight': 1.0, 'voltage': 2.0, 'wattage': 3.0}\n",
        "    return entity_map.get(entity, 0.0)  # Default to 0 if entity not found\n",
        "\n",
        "train_df['predicted_entity_numeric'] = train_df['predicted_entity'].apply(entity_to_numeric)\n",
        "\n",
        "# Ensemble predictions: average CNN model output and OCR predictions\n",
        "cnn_predictions = cnn_model.predict(X_images).flatten()\n",
        "\n",
        "# Ensure both columns are numeric before averaging\n",
        "train_df['ensemble_pred'] = (train_df['predicted_entity_numeric'] + cnn_predictions) / 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwgREswDSOkS",
        "outputId": "3f73456d-d3bb-46a6-fe61-c006e4c07ff3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "def load_image_from_url(image_url, target_size=(128, 128)):\n",
        "    try:\n",
        "        response = requests.get(image_url)\n",
        "        img = Image.open(BytesIO(response.content))\n",
        "        img = img.convert('RGB')  # Ensure image is RGB\n",
        "        img = img.resize(target_size)  # Resize images to standard size\n",
        "        img = np.array(img)\n",
        "        return img / 255.0  # Normalize image\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image from {image_url}: {e}\")\n",
        "        # Return a blank image in case of an error\n",
        "        return np.zeros((*target_size, 3))\n",
        "\n",
        "def preprocess_images(image_urls, target_size=(128, 128)):\n",
        "    images = []\n",
        "    for url in image_urls:\n",
        "        img = load_image_from_url(url, target_size)\n",
        "        if img.shape != (*target_size, 3):\n",
        "            print(f\"Unexpected image shape: {img.shape}\")\n",
        "            img = np.zeros((*target_size, 3))  # Replace with a blank image if shape is incorrect\n",
        "        images.append(img)\n",
        "    images_array = np.array(images)\n",
        "    return images_array\n",
        "\n",
        "# Example usage for test data\n",
        "test_image_urls = test_df['image_link'].values  # Assuming image URLs are in 'image_link'\n",
        "test_images = preprocess_images(test_image_urls)\n",
        "print(f\"Shape of test_images: {test_images.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjbiDJH0gKIt",
        "outputId": "4d08fd58-7589-49a0-a087-49fc0630efe7"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def preprocess_and_stack_images(image_data_list, target_size=(128, 128)):\n",
        "    \"\"\"\n",
        "    Resize and preprocess images to ensure they all have the same shape.\n",
        "\n",
        "    Args:\n",
        "        image_data_list (list of numpy arrays): List of image data arrays.\n",
        "        target_size (tuple): Target size for the images (height, width).\n",
        "\n",
        "    Returns:\n",
        "        numpy array: Stacked array of preprocessed images.\n",
        "    \"\"\"\n",
        "    processed_images = []\n",
        "\n",
        "    for img in image_data_list:\n",
        "        # Check if img is grayscale (2D) or RGB (3D)\n",
        "        if img.ndim == 2:  # Grayscale image\n",
        "            img = np.stack([img] * 3, axis=-1)  # Convert grayscale to RGB\n",
        "        elif img.ndim == 3 and img.shape[-1] == 4:  # RGBA image\n",
        "            img = img[..., :3]  # Remove alpha channel\n",
        "        elif img.ndim != 3 or img.shape[-1] not in [1, 3]:  # Unexpected number of channels\n",
        "            raise ValueError(f\"Unexpected image format. Expected grayscale or RGB with 1 or 3 channels, got {img.ndim}D with shape {img.shape}.\")\n",
        "\n",
        "        # Resize image\n",
        "        img_resized = cv2.resize(img, target_size[::-1])  # Resize to target size (width, height)\n",
        "\n",
        "        # Check image has 3 channels\n",
        "        if img_resized.shape[-1] != 3:\n",
        "            raise ValueError(f\"Unexpected number of channels in resized image. Expected 3, got {img_resized.shape[-1]}.\")\n",
        "\n",
        "        processed_images.append(img_resized)\n",
        "\n",
        "    return np.array(processed_images)\n",
        "\n",
        "# Ensure test images have the same shape\n",
        "test_image_data_list = test_df['image_data'].values\n",
        "test_images = preprocess_and_stack_images(test_image_data_list)\n",
        "\n",
        "# Predictions on test data\n",
        "cnn_predictions = cnn_model.predict(test_images).flatten()\n",
        "\n",
        "# Ensure y_true and y_pred are numeric and handle NaNs if necessary\n",
        "y_true = pd.to_numeric(train_df['entity_value'], errors='coerce').fillna(0).values\n",
        "y_pred = pd.to_numeric(train_df['ensemble_pred'], errors='coerce').fillna(0).values\n",
        "\n",
        "# Ensure the predictions and true values are compatible for F1 score calculation\n",
        "# If you are using regression, the F1 score might not be suitable; consider other metrics\n",
        "if len(y_true) == len(y_pred):\n",
        "    # For demonstration, using rounded values for binary classification example\n",
        "    f1 = f1_score(y_true.round(), y_pred.round(), average='macro')\n",
        "    print(f'Final F1 Score: {f1}')\n",
        "else:\n",
        "    print('Mismatch in length of true values and predictions.')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
